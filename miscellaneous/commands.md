# Some Commands

```bash
docker-compose up -d --build mysql
# docker-compose logs -f mysql
sleep 10

# docker-compose up -d elasticsearch
# sleep 10

docker-compose up -d zookeeper kafka
# docker-compose logs -f zookeeper kafka
sleep 10


# API for sink
docker-compose up -d --build api
# docker-compose logs -f api
sleep 10


docker-compose up -d --build kafka-connect
# docker-compose logs -f kafka-connect
sleep 10

docker-compose up -d --build kafka-connect-setup
# docker-compose logs -f kafka-connect-setup
sleep 10

docker-compose up -d control-center
# docker-compose logs -f control-center
sleep 10


# clients
docker-compose up -d --build producer
# docker-compose logs -f producer
sleep 10

docker-compose up -d --build consumer
# docker-compose logs -f consumer
sleep 10



# kafka docker
docker-compose exec kafka sh -c \
  'kafka-topics --zookeeper $KAFKA_ZOOKEEPER_CONNECT --create --topic topic_0 --partitions 1 --replication-factor 1 --if-not-exists'

docker exec -it kafka sh -c \
  'kafka-topics --zookeeper $KAFKA_ZOOKEEPER_CONNECT --list | egrep -v "^_"'

# produce some message
docker exec -it kafka sh -c \
  'kafka-console-producer --broker-list 127.0.0.1:9092 --topic topic_0'



for i in {1..10}; do
  mysql -u root -padmin -h 127.0.0.1 -P 3336 -e "INSERT INTO kafka_database.users (name, email, password) VALUES ('teste_$RANDOM', 'teste_$RANDOM@mail.com', 'password-$RANDOM');"
done

mysql -u root -padmin -h 127.0.0.1 -P 3336 -e "SELECT CAST(id AS UNSIGNED) AS id, name, email, password, created_at, updated_at, deleted_at FROM kafka_database.users"


mysql -u root -padmin -h 127.0.0.1 -P 3336

INSERT INTO kafka_database.users (name, email, password) VALUES ('teste_1000', 'teste_1000@mail.com', 'password-1000');

docker exec -it mysql mysql -u root -padmin -h 127.0.0.1 -P 3306

SHOW SCHEMAS;
SELECT * FROM kafka_database.users;

docker exec -it mysql sh -c \
  'mysql -u root -padmin -h 127.0.0.1 -P 3306 -e "SHOW SCHEMAS"'

docker exec -it mysql sh -c \
  'mysql -u root -padmin -h 127.0.0.1 -P 3306 -e "TRUNCATE TABLE kafka_database.users"'

(
cat <<EOF
INSERT INTO kafka_database.users (name, email, password) VALUES ('teste_${RANDOM}', 'teste_${RANDOM}@mail.com', 'password-${RANDOM}')
EOF
) | docker exec -i mysql sh -c \
  "cat - > out.sql && mysql -u root -padmin -h 127.0.0.1 -P 3306 < out.sql"

docker exec -it mysql sh -c \
  'mysql -u root -padmin -h 127.0.0.1 -P 3306 -e "SELECT * FROM kafka_database.users"'


# consume topic generated by debezium
docker-compose exec kafka sh -c \
  'kafka-console-consumer --bootstrap-server kafka:9092 --topic mysql-namespace.kafka_database.users'



docker exec -it kafka-connect sh
curl http://kafka-connect:8083/connectors


confluent-hub install --no-prompt debezium/debezium-connector-mysql:1.2.2
confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:10.0.1
/etc/confluent/docker/run &
sleep infinity



# docker
docker container run --rm -it --volume $PWD/:/app/ --name java openjdk:12 sh

docker image build --tag juliocesarmidia/java-kafka:latest .

docker container run --rm \
  --name java-kafka -m 800M \
  -e JAVA_OPTIONS='-Xmx400m' -p 8000:8080 \
  juliocesarmidia/java-kafka:latest
```
